{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52c2247c-b724-416a-993e-dcde181b88aa",
   "metadata": {},
   "source": [
    "## 0）Setup and Styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7e230a9-6d21-4e29-b672-9b71a6f5e37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Init] SAVE_DIR: ./runs_demo | FIG_DIR: ./runs_demo/stage6_explain1\n"
     ]
    }
   ],
   "source": [
    "import os, json, numpy as np, pandas as pd, matplotlib.pyplot as plt, matplotlib as mpl\n",
    "from pathlib import Path\n",
    "\n",
    "# Directories\n",
    "SAVE_DIR = \"./runs_demo\"\n",
    "FIG_DIR  = os.path.join(SAVE_DIR, \"stage6_explain\")\n",
    "DATA_PATH = \"./data/global_clean.csv\"   # For rebuilding X_df/feat_cols\n",
    "Path(FIG_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Paper-ready style\n",
    "mpl.rcParams.update({\n",
    "    \"figure.dpi\": 160, \"savefig.dpi\": 320,\n",
    "    \"font.size\": 11, \"axes.titlesize\": 13,\n",
    "    \"axes.labelsize\": 11, \"xtick.labelsize\": 10, \"ytick.labelsize\": 10,\n",
    "    \"axes.spines.top\": False, \"axes.spines.right\": False,\n",
    "    \"axes.grid\": False, \"legend.frameon\": False,\n",
    "    \"pdf.fonttype\": 42, \"ps.fonttype\": 42,   \n",
    "})\n",
    "\n",
    "# Colors\n",
    "COL_XGB, COL_LGB = \"#4E79A7\", \"#F28E2B\"\n",
    "COL_LINE = \"#9aa0a6\"\n",
    "\n",
    "def safe_savefig(fig, out_base):\n",
    "    for ext in (\"png\",\"pdf\",\"svg\"):\n",
    "        fig.savefig(f\"{out_base}.{ext}\", bbox_inches=\"tight\", dpi=320)\n",
    "\n",
    "print(\"[Init] SAVE_DIR:\", SAVE_DIR, \"| FIG_DIR:\", FIG_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb08cc0d-4b30-4a83-9ccf-0af6573d0a73",
   "metadata": {},
   "source": [
    "## 1) Rebuild X_df / feat_cols / df_meta (from CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2e15411-edaf-4a03-a97f-410f856f34bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Data] rows = 284558 | n_features = 18\n",
      "[Data] feat preview: ['latitude', 'longitude', 'topo', 'topo_smoothed', 'slope', 'slope_factor', 'aspect', 'dis_from_border', 'catchment_area', 'millan_v', 'glacier_cenlon', 'glacier_cenlat']\n",
      "[Meta] cols: ['RGI']\n"
     ]
    }
   ],
   "source": [
    "drop_cols_hard = [\n",
    "    \"Unnamed: 0\",\"ij_grid\",\"i_grid\",\"j_grid\",\"x_proj\",\"y_proj\",\"survey_id\",\"date\",\"rgi_id\",\n",
    "    \"consensus_ice_thickness\",\"millan_ice_thickness\",\"itslive_v\",\"hugonnet_dhdt\",\n",
    "    \"glacier_length\",\"glacier_area_km2\",\"glacier_oggm_volume\",\n",
    "    \"glacier_min_elev\",\"glacier_max_elev\",\"glacier_median_elev\",\"glacier_outline_year\",\n",
    "    \"lin_mb_above_z\",\"oggm_mb_above_z\",\"thickness_uncertainty\",\n",
    "]\n",
    "TARGET_COL = \"thickness\"\n",
    "\n",
    "df_raw = pd.read_csv(DATA_PATH, low_memory=False)\n",
    "df = df_raw.drop(columns=[c for c in drop_cols_hard if c in df_raw.columns], errors=\"ignore\").copy()\n",
    "assert TARGET_COL in df.columns, f\"Target '{TARGET_COL}' missing.\"\n",
    "\n",
    "RGI_COL   = \"RGI\" if \"RGI\" in df.columns else (\"region\" if \"region\" in df.columns else None)\n",
    "ID_COL    = \"glacier_id\" if \"glacier_id\" in df.columns else None\n",
    "NAME_COL  = \"glacier_name\" if \"glacier_name\" in df.columns else None\n",
    "\n",
    "exclude_cols = {TARGET_COL, \"lat\", \"lon\", \"year\", \"date\"}\n",
    "for c in (RGI_COL, ID_COL, NAME_COL):\n",
    "    if c: exclude_cols.add(c)\n",
    "\n",
    "num_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "std0_cols = [c for c in num_df.columns if num_df[c].nunique(dropna=True) <= 1]\n",
    "num_df = num_df.drop(columns=std0_cols, errors=\"ignore\")\n",
    "\n",
    "feat_cols = [c for c in num_df.columns if c not in exclude_cols]\n",
    "X_df = df[feat_cols].astype(\"float32\").replace([np.inf, -np.inf], np.nan)\n",
    "y_sr = df[TARGET_COL].astype(\"float32\")\n",
    "\n",
    "row_mask = ~(X_df.isna().any(axis=1) | y_sr.isna())\n",
    "X_df, y_sr, df = X_df.loc[row_mask], y_sr.loc[row_mask], df.loc[row_mask].reset_index(drop=True)\n",
    "\n",
    "meta_path = os.path.join(SAVE_DIR, \"df_meta.csv\")\n",
    "if os.path.exists(meta_path):\n",
    "    df_meta = pd.read_csv(meta_path)\n",
    "    if len(df_meta) != len(df):\n",
    "        df_meta = df[[c for c in [\"glacier_name\",\"RGI\",\"glacier_id\"] if c in df.columns]].copy()\n",
    "else:\n",
    "    df_meta = df[[c for c in [\"glacier_name\",\"RGI\",\"glacier_id\"] if c in df.columns]].copy()\n",
    "\n",
    "print(\"[Data] rows =\", len(df), \"| n_features =\", len(feat_cols))\n",
    "print(\"[Data] feat preview:\", feat_cols[:12])\n",
    "print(\"[Meta] cols:\", list(df_meta.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b477d7c-accc-43c9-a1aa-888c90b8c220",
   "metadata": {},
   "source": [
    "## 2) Utilities for importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "609e5aa9-ae5a-4f74-b877-0d69a635735f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imp_pct(csv_path):\n",
    "    \"\"\"Read (feature, importance) → Return (feature, pct), where pct sums to 100.\"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.columns = [c.lower().strip() for c in df.columns]\n",
    "    s = df[\"importance\"].sum()\n",
    "    df[\"pct\"] = (df[\"importance\"] / s * 100.0) if s > 0 else 0.0\n",
    "    return df[[\"feature\",\"pct\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9c2d0e-4981-4753-9573-defc7e3133fe",
   "metadata": {},
   "source": [
    "## 3) Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feda155f-8830-42bb-a88d-4c2fc7e73e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved] ./runs_demo/stage6_explain1/fig_importance_2x2_top15_no_share_axes\n"
     ]
    }
   ],
   "source": [
    "TOPK = 15\n",
    "paths = {\n",
    "    \"builtin_xgb\": os.path.join(FIG_DIR, \"imp_builtin_xgboost.csv\"),\n",
    "    \"builtin_lgb\": os.path.join(FIG_DIR, \"imp_builtin_lightgbm.csv\"),\n",
    "    \"perm_xgb\":    os.path.join(FIG_DIR, \"imp_perm_xgboost.csv\"),\n",
    "    \"perm_lgb\":    os.path.join(FIG_DIR, \"imp_perm_lightgbm.csv\"),\n",
    "}\n",
    "\n",
    "# Read and convert to percentage\n",
    "bx = load_imp_pct(paths[\"builtin_xgb\"])\n",
    "bl = load_imp_pct(paths[\"builtin_lgb\"])\n",
    "px = load_imp_pct(paths[\"perm_xgb\"])\n",
    "pl = load_imp_pct(paths[\"perm_lgb\"])\n",
    "\n",
    "def _wrap(s, width=20):\n",
    "    s = str(s).replace(\"_\", \"·\")\n",
    "    if len(s) <= width: return s\n",
    "    out, line = [], \"\"\n",
    "    for ch in s:\n",
    "        line += ch\n",
    "        if len(line) >= width:\n",
    "            out.append(line); line = \"\"\n",
    "    if line: out.append(line)\n",
    "    return \"\\n\".join(out)\n",
    "\n",
    "def plot_panel(ax, df, color, title, tag, topk=15):\n",
    "    \"\"\"Each panel independently: sorted descending, white background, no grid, independent y-axis categories & limits.\"\"\"\n",
    "    d = (df.sort_values(\"pct\", ascending=False)\n",
    "           .head(topk)\n",
    "           .reset_index(drop=True))\n",
    "    feats = d[\"feature\"].tolist()\n",
    "    vals  = d[\"pct\"].to_numpy()\n",
    "\n",
    "    # White background + clean axes\n",
    "    ax.set_facecolor(\"white\")\n",
    "    for side in (\"top\",\"right\"):\n",
    "        ax.spines[side].set_visible(False)\n",
    "    ax.grid(False)\n",
    "\n",
    "    # Independent y-axis: each subplot sets yticks/labels and ylim individually\n",
    "    y = np.arange(len(feats))\n",
    "    bars = ax.barh(y, vals, color=color, height=0.64, align=\"center\")\n",
    "    ax.set_yticks(y)\n",
    "    ax.set_yticklabels([_wrap(f) for f in feats], fontsize=10)\n",
    "    ax.set_ylim(-0.5, len(feats)-0.5)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    # x-axis (adjust to each subplot’s range)\n",
    "    xmax = 1.06 * vals.max() if len(vals) else 1.0\n",
    "    ax.set_xlim(0, xmax)\n",
    "    ax.set_xlabel(\"Importance (%)\")\n",
    "    ax.set_title(f\"{tag}. {title}\", loc=\"center\")\n",
    "\n",
    "    # Add value annotations at the end of bars\n",
    "    pad = 0.6 if xmax <= 10 else 0.8\n",
    "    for b, v in zip(bars, vals):\n",
    "        x = min(v + pad, xmax - pad*0.4)\n",
    "        ax.text(x, b.get_y() + b.get_height()/2, f\"{v:.2f}\",\n",
    "                ha=\"left\", va=\"center\", fontsize=9)\n",
    "\n",
    "# 2x2 subplot without shared axes\n",
    "fig_h = max(7.0, 0.45 * TOPK * 2)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14.2, fig_h))\n",
    "fig.set_facecolor(\"white\")\n",
    "\n",
    "plot_panel(axes[0,0], bx, COL_XGB, \"Built-in Importance (XGB)\", \"a\", TOPK)\n",
    "plot_panel(axes[0,1], bl, COL_LGB, \"Built-in Importance (LGB)\", \"b\", TOPK)\n",
    "plot_panel(axes[1,0], px, COL_XGB, \"Permutation Importance (XGB)\", \"c\", TOPK)\n",
    "plot_panel(axes[1,1], pl, COL_LGB, \"Permutation Importance (LGB)\", \"d\", TOPK)\n",
    "\n",
    "plt.tight_layout()\n",
    "out_base = os.path.join(FIG_DIR, f\"fig_importance_2x2_top{TOPK}_no_share_axes\")\n",
    "safe_savefig(fig, out_base)\n",
    "plt.close(fig)\n",
    "print(\"[Saved]\", out_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8262391-2805-45c8-9034-fa0c56bd62a3",
   "metadata": {},
   "source": [
    "## 4)Importance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36849475-d8fa-4083-9dd1-23cfb0f679b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved] ./runs_demo/stage6_explain1/fig_dumbbell_delta_2x1_centered_wide.png / .pdf / .svg\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Colors\n",
    "COL_XGB  = globals().get(\"COL_XGB\",  \"#4E79A7\")\n",
    "COL_LGB  = globals().get(\"COL_LGB\",  \"#F28E2B\")\n",
    "COL_LINE = globals().get(\"COL_LINE\", \"#bfc4cc\")\n",
    "\n",
    "# Canvas and axis length settings\n",
    "FIG_W         = 16.0\n",
    "TITLE_FSIZE   = 14\n",
    "X_PAD_RATIO   = 0.12\n",
    "\n",
    "def prep_diff(xgb_csv, lgb_csv, topk=15):\n",
    "    a = load_imp_pct(xgb_csv).rename(columns={\"pct\": \"XGB\"})\n",
    "    b = load_imp_pct(lgb_csv).rename(columns={\"pct\": \"LGB\"})\n",
    "    m = a.merge(b, on=\"feature\", how=\"outer\").fillna(0.0)\n",
    "    m[\"diff\"] = (m[\"XGB\"] - m[\"LGB\"]).abs()\n",
    "    return (m.sort_values(\"diff\", ascending=False)\n",
    "             .head(topk)\n",
    "             .reset_index(drop=True))\n",
    "\n",
    "TOPK = 15\n",
    "built_df = prep_diff(paths[\"builtin_xgb\"], paths[\"builtin_lgb\"], TOPK)\n",
    "perm_df  = prep_diff(paths[\"perm_xgb\"],    paths[\"perm_lgb\"],    TOPK)\n",
    "\n",
    "def _format_axis(ax):\n",
    "    ax.set_facecolor(\"white\")\n",
    "    for s in (\"top\",\"right\"):\n",
    "        ax.spines[s].set_visible(False)\n",
    "    ax.grid(False)\n",
    "    ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=7))\n",
    "    ax.xaxis.set_major_formatter(mpl.ticker.FormatStrFormatter(\"%.0f\"))\n",
    "\n",
    "def draw_simple_dumbbell(ax, df, title, show_legend=False):\n",
    "    _format_axis(ax)\n",
    "    n = len(df); y = np.arange(n)\n",
    "\n",
    "    lgb = df[\"LGB\"].to_numpy()\n",
    "    xgb = df[\"XGB\"].to_numpy()\n",
    "\n",
    "    # Gray line connections\n",
    "    left  = np.minimum(lgb, xgb)\n",
    "    right = np.maximum(lgb, xgb)\n",
    "    ax.hlines(y, left, right, color=COL_LINE, linewidth=2.0, zorder=1)\n",
    "\n",
    "    # Dots\n",
    "    p_lgb = ax.scatter(lgb, y, s=42, color=COL_LGB, marker=\"o\", zorder=2, label=\"LGB\")\n",
    "    p_xgb = ax.scatter(xgb, y, s=42, color=COL_XGB, marker=\"o\", zorder=3, label=\"XGB\")\n",
    "\n",
    "    # y-axis\n",
    "    ax.set_yticks(y)\n",
    "    ax.set_yticklabels(df[\"feature\"], fontsize=10)\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    # Extended x-axis (add X_PAD_RATIO padding to max value)\n",
    "    xmax = float(np.max(np.r_[lgb, xgb])) if n else 1.0\n",
    "    ax.set_xlim(0, xmax * (1.0 + X_PAD_RATIO))\n",
    "    ax.set_xlabel(\"Importance (%)\")\n",
    "\n",
    "    # Centered title\n",
    "    ax.set_title(title, loc=\"center\", fontsize=TITLE_FSIZE, pad=6)\n",
    "\n",
    "    if show_legend:\n",
    "        ax.legend(loc=\"lower right\", frameon=False, ncols=2, fontsize=9)\n",
    "\n",
    "# 2×1 layout (vertical), no shared axes\n",
    "fig_h = max(6.0, 0.45 * TOPK) * 2 + 0.8\n",
    "fig, axes = plt.subplots(2, 1, figsize=(FIG_W, fig_h), sharex=False, sharey=False)\n",
    "fig.set_facecolor(\"white\")\n",
    "\n",
    "draw_simple_dumbbell(axes[0], built_df, \"a. Built-in Importance (sorted by abs diff)\", show_legend=False)\n",
    "draw_simple_dumbbell(axes[1], perm_df,  \"b. Permutation Importance (sorted by abs diff)\", show_legend=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "out_base = os.path.join(FIG_DIR, \"fig_dumbbell_delta_2x1_centered_wide\")\n",
    "safe_savefig(fig, out_base)\n",
    "plt.close(fig)\n",
    "print(\"[Saved]\", out_base + \".png / .pdf / .svg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b6f94c-35ac-4f59-a81a-029d38d30686",
   "metadata": {},
   "source": [
    "## 5) SHAP Beeswarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c738fac-9f0e-4f25-b1b8-14c7d2032544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved] ./runs_demo/stage6_explain1/fig_shap_beeswarm_shared\n"
     ]
    }
   ],
   "source": [
    "# Requires stage6_explain/xgb_shap_subset.npy & lgb_shap_subset.npy\n",
    "sv_xgb = np.load(os.path.join(FIG_DIR, \"xgb_shap_subset.npy\"))\n",
    "sv_lgb = np.load(os.path.join(FIG_DIR, \"lgb_shap_subset.npy\"))\n",
    "\n",
    "# Ensure feature names align with column order\n",
    "assert sv_xgb.shape[1] == sv_lgb.shape[1] == len(feat_cols), \"SHAP shape != feature count\"\n",
    "\n",
    "# Sorting rule: average of mean(|SHAP|) from both models\n",
    "imp_x = np.abs(sv_xgb).mean(0)\n",
    "imp_l = np.abs(sv_lgb).mean(0)\n",
    "order = np.argsort(-(imp_x + imp_l)/2)\n",
    "\n",
    "X_sub = pd.DataFrame(X_df.to_numpy()[:sv_xgb.shape[0], :], columns=feat_cols)\n",
    "\n",
    "import shap\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6), sharey=True)\n",
    "\n",
    "plt.sca(axes[0])\n",
    "shap.summary_plot(sv_xgb[:, order], X_sub.iloc[:, order], show=False, plot_size=None)\n",
    "axes[0].set_title(\"a. SHAP Beeswarm (XGB; shared order & x-range)\")\n",
    "xlim_shared = axes[0].get_xlim()\n",
    "\n",
    "plt.sca(axes[1])\n",
    "shap.summary_plot(sv_lgb[:, order], X_sub.iloc[:, order], show=False, plot_size=None)\n",
    "axes[1].set_title(\"b. SHAP Beeswarm (LGB; shared order & x-range)\")\n",
    "axes[1].set_xlim(xlim_shared)\n",
    "\n",
    "plt.tight_layout()\n",
    "out_base = os.path.join(FIG_DIR, \"fig_shap_beeswarm_shared\")\n",
    "safe_savefig(fig, out_base)\n",
    "plt.close(fig)\n",
    "print(\"[Saved]\", out_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ee90b8-9c5e-45f6-944e-5e77c39b8f3a",
   "metadata": {},
   "source": [
    "## 6) SHAP Dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30bacfeb-d155-4468-8e7e-528b26ad9844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3654/3263754386.py:26: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout(rect=[0,0,0.9,1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved] ./runs_demo/stage6_explain1/fig_shap_dependence_top3_sharedcbar\n"
     ]
    }
   ],
   "source": [
    "# Select Top-3 (same sorting as in Cell 5)\n",
    "top3_idx = order[:3]\n",
    "top3_names = [feat_cols[i] for i in top3_idx]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 8))\n",
    "cmap = plt.get_cmap(\"viridis\")\n",
    "norm = plt.Normalize(X_sub[top3_names[2]].min(), X_sub[top3_names[2]].max())  # Use 3rd feature for shared colorbar\n",
    "\n",
    "for j, fid in enumerate(top3_idx):\n",
    "    # XGB\n",
    "    ax = axes[0, j]\n",
    "    sc = ax.scatter(X_sub.iloc[:, fid], sv_xgb[:, fid], c=X_sub.iloc[:, top3_idx[2]], s=8, cmap=cmap, norm=norm)\n",
    "    ax.set_xlabel(feat_cols[fid]); ax.set_ylabel(f\"SHAP({feat_cols[fid]})\")\n",
    "    ax.set_title(f\"a{j+1}. XGB — {feat_cols[fid]}\")\n",
    "    # LGB\n",
    "    ax = axes[1, j]\n",
    "    ax.scatter(X_sub.iloc[:, fid], sv_lgb[:, fid], c=X_sub.iloc[:, top3_idx[2]], s=8, cmap=cmap, norm=norm)\n",
    "    ax.set_xlabel(feat_cols[fid]); ax.set_ylabel(f\"SHAP({feat_cols[fid]})\")\n",
    "    ax.set_title(f\"b{j+1}. LGB — {feat_cols[fid]}\")\n",
    "\n",
    "# Shared colorbar\n",
    "cax = fig.add_axes([0.92, 0.15, 0.015, 0.7])\n",
    "cb = plt.colorbar(plt.cm.ScalarMappable(norm=norm, cmap=cmap), cax=cax)\n",
    "cb.set_label(f\"{feat_cols[top3_idx[2]]} (shared)\")\n",
    "\n",
    "plt.tight_layout(rect=[0,0,0.9,1])\n",
    "out_base = os.path.join(FIG_DIR, \"fig_shap_dependence_top3_sharedcbar\")\n",
    "safe_savefig(fig, out_base)\n",
    "plt.close(fig)\n",
    "print(\"[Saved]\", out_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4fdc37-a7e2-400b-9d8f-50f3a0bd5d00",
   "metadata": {},
   "source": [
    "## 7) Local SHAP — Force-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46a0c17e-6151-4236-8baf-c606a0e0700f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved] XGB force  -> ./runs_demo/stage6_explain1/force_xgb_ultra.png\n",
      "[Saved] LGB force  -> ./runs_demo/stage6_explain1/force_lgb_ultra.png\n",
      "[Saved] Force-wide stack -> ./runs_demo/stage6_explain1/fig_local_force_stack_RGI_RGI01.png\n"
     ]
    }
   ],
   "source": [
    "import os, re, json, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------- Paths ----------\n",
    "SAVE_DIR  = \"./runs_demo\"\n",
    "FIG_DIR   = os.path.join(SAVE_DIR, \"stage6_explain1\")   # Directory for current cell's outputs\n",
    "BLEND_DIR = os.path.join(SAVE_DIR, \"stage4_best_blend\") # Load pre-trained models if available\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "\n",
    "# ---------- Expect S1 in memory ----------\n",
    "# Relies on variables df / X_df / y_sr already set in S1\n",
    "assert \"df\" in globals() and \"X_df\" in globals() and \"y_sr\" in globals(), \\\n",
    "    \"Please run S1 first to ensure df / X_df / y_sr are loaded into memory.\"\n",
    "\n",
    "# ---------- Read Metadata and Select Target Sample ----------\n",
    "meta_path = os.path.join(SAVE_DIR, \"df_meta.csv\")\n",
    "if os.path.exists(meta_path):\n",
    "    df_meta = pd.read_csv(meta_path)\n",
    "    if 'index' in df_meta.columns:\n",
    "        df_meta = df_meta.drop(columns=['index'])\n",
    "    if len(df_meta) != len(X_df):\n",
    "        df_meta = df[[c for c in [\"glacier_name\",\"RGI\",\"glacier_id\"] if c in df.columns]].reset_index(drop=True)\n",
    "else:\n",
    "    df_meta = df[[c for c in [\"glacier_name\",\"RGI\",\"glacier_id\"] if c in df.columns]].reset_index(drop=True)\n",
    "\n",
    "ID_COL = \"glacier_name\" if \"glacier_name\" in df_meta.columns else (\"RGI\" if \"RGI\" in df_meta.columns else \"glacier_id\")\n",
    "\n",
    "TARGET_KEY_OVERRIDE = None  # You can also specify a specific glacier name or region here\n",
    "target_key = df_meta[ID_COL].iloc[0] if TARGET_KEY_OVERRIDE is None else TARGET_KEY_OVERRIDE\n",
    "row_idx = int(df_meta.index[df_meta[ID_COL] == target_key][0])\n",
    "\n",
    "row_df  = X_df.iloc[row_idx:row_idx+1]\n",
    "row_np  = row_df.values[0]\n",
    "feat_names = row_df.columns.tolist()\n",
    "baseline_value = float(np.nanmean(y_sr))\n",
    "\n",
    "# ---------- Read/Calculate SHAP (Robust) ----------\n",
    "def _load_model_try(path):\n",
    "    try:\n",
    "        import joblib\n",
    "        return joblib.load(path) if os.path.exists(path) else None\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] Model loading failed:\", e); return None\n",
    "\n",
    "def _explain_tree(model, row_df):\n",
    "    try:\n",
    "        exp = shap.TreeExplainer(model)(row_df)\n",
    "        base = float(np.asarray(exp.base_values).reshape(-1)[0])\n",
    "        vals = np.asarray(exp.values).reshape(-1)\n",
    "        dat  = np.asarray(exp.data).reshape(-1)\n",
    "        return shap.Explanation(values=vals, base_values=base, data=dat,\n",
    "                                feature_names=row_df.columns.tolist())\n",
    "    except Exception as e:\n",
    "        print(\"[WARN] SHAP calculation failed:\", e); return None\n",
    "\n",
    "sv_xgb = None; sv_lgb = None\n",
    "mx = _load_model_try(os.path.join(BLEND_DIR, \"xgb_final.pkl\"))\n",
    "ml = _load_model_try(os.path.join(BLEND_DIR, \"lgb_final.pkl\"))\n",
    "if mx is not None: sv_xgb = _explain_tree(mx, row_df)\n",
    "if ml is not None: sv_lgb = _explain_tree(ml, row_df)\n",
    "\n",
    "# Fallback to saved .npy (first search default directory, then in current directory)\n",
    "def _try_load_npy():\n",
    "    for d in (os.path.join(SAVE_DIR, \"stage6_explain\"), FIG_DIR):\n",
    "        npy_x = os.path.join(d, \"xgb_shap_subset.npy\")\n",
    "        npy_l = os.path.join(d, \"lgb_shap_subset.npy\")\n",
    "        if os.path.exists(npy_x) and os.path.exists(npy_l):\n",
    "            arr_x = np.load(npy_x); arr_l = np.load(npy_l)\n",
    "            if row_idx < arr_x.shape[0] and row_idx < arr_l.shape[0]:\n",
    "                return arr_x[row_idx], arr_l[row_idx]\n",
    "    return None, None\n",
    "\n",
    "if sv_xgb is None or sv_lgb is None:\n",
    "    axv, alv = _try_load_npy()\n",
    "    if (sv_xgb is None) and (axv is not None):\n",
    "        sv_xgb = shap.Explanation(values=axv, base_values=baseline_value,\n",
    "                                  data=row_np, feature_names=feat_names)\n",
    "    if (sv_lgb is None) and (alv is not None):\n",
    "        sv_lgb = shap.Explanation(values=alv, base_values=baseline_value,\n",
    "                                  data=row_np, feature_names=feat_names)\n",
    "\n",
    "# Last fallback: zero vector\n",
    "if sv_xgb is None: sv_xgb = shap.Explanation(np.zeros_like(row_np), baseline_value, row_np, feat_names)\n",
    "if sv_lgb is None: sv_lgb = shap.Explanation(np.zeros_like(row_np), baseline_value, row_np, feat_names)\n",
    "\n",
    "# ---------- Rename for Simplicity (Avoid Long Names) ----------\n",
    "RENAME = {\n",
    "    \"dis_from_border\":\"dist_border\", \"catchment_area\":\"catch_area\",\n",
    "    \"topo_smoothed\":\"topo_smooth\", \"slope_factor\":\"slope_f\",\n",
    "    \"glacier_cenlon\":\"g_cenlon\", \"glacier_cenlat\":\"g_cenlat\",\n",
    "    \"glacier_aar\":\"g_aar\", \"glacier_reference_mb\":\"ref_mb\"\n",
    "}\n",
    "def _short(n): return RENAME.get(n, n).replace(\"__\",\"_\")\n",
    "def _ren(sv): return shap.Explanation(values=sv.values, base_values=sv.base_values,\n",
    "                                      data=sv.data, feature_names=[_short(n) for n in sv.feature_names])\n",
    "sv_xgb, sv_lgb = _ren(sv_xgb), _ren(sv_lgb)\n",
    "\n",
    "# ---------- Plot: No Overlap Force (Ultra Wide Canvas + Move Text Out of Way) ----------\n",
    "mpl.rcParams.update({\"font.family\":\"DejaVu Sans\",\"font.size\":11, \"figure.dpi\":150})\n",
    "\n",
    "def _safe_save(fig, base):\n",
    "    for ext in (\"png\",\"pdf\",\"svg\"):\n",
    "        fig.savefig(f\"{base}.{ext}\", bbox_inches=\"tight\", dpi=320)\n",
    "\n",
    "def save_force_clean(sv, out_base, top_k=12, figsize=(19.0, 3.1)):\n",
    "    \"\"\"\n",
    "    Force plot (ultimate version to prevent overlap):\n",
    "      1) Keep only Top-K feature names\n",
    "      2) Remove SHAP native 'higher'/'lower'/'f(x)'/'base value'\n",
    "      3) Replot these texts above the figure to prevent overlap with colorbar\n",
    "    \"\"\"\n",
    "    order = np.argsort(-np.abs(sv.values))[:top_k]\n",
    "    vals  = np.asarray(sv.values)[order]\n",
    "    names = [sv.feature_names[i] for i in order]\n",
    "    base  = float(np.asarray(sv.base_values).reshape(-1)[0])\n",
    "    fx    = base + float(vals.sum())\n",
    "\n",
    "    fig = shap.plots.force(base, vals, features=None, feature_names=names,\n",
    "                           matplotlib=True, show=False)\n",
    "    fig.set_size_inches(*figsize)\n",
    "    ax = fig.axes[0]\n",
    "\n",
    "    # Top padding: move content down and leave enough space for the text at the top\n",
    "    fig.subplots_adjust(left=0.05, right=0.995, bottom=0.32, top=0.72)\n",
    "\n",
    "    # Remove overlapping native SHAP text\n",
    "    for t in list(ax.texts):\n",
    "        s = t.get_text().strip()\n",
    "        if s in (\"higher\", \"lower\", \"f(x)\", \"base value\"):\n",
    "            t.remove(); continue\n",
    "        ss = s.replace(\",\", \"\")\n",
    "        if re.fullmatch(r\"-?\\d+(\\.\\d+)?\", ss) and t.get_fontsize() >= 14:\n",
    "            t.remove()\n",
    "\n",
    "    # Re-draw these texts outside the figure to avoid overlap with colorbar\n",
    "    fig.text(0.20, 0.93, \"higher\", color=\"#ff2c6d\", ha=\"center\", va=\"bottom\")\n",
    "    fig.text(0.50, 0.91, \"f(x)\",    color=\"#787878\", ha=\"center\", va=\"bottom\")\n",
    "    fig.text(0.80, 0.93, \"lower\",  color=\"#1f77b4\", ha=\"center\", va=\"bottom\")\n",
    "    fig.text(0.50, 0.865, f\"{fx:.2f}\", ha=\"center\", va=\"bottom\",\n",
    "             fontsize=18, fontweight=\"bold\", color=\"black\")\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    _safe_save(fig, out_base)\n",
    "    plt.close(fig)\n",
    "\n",
    "# Save individual images\n",
    "fx_path = os.path.join(FIG_DIR, \"force_xgb_ultra\")\n",
    "fl_path = os.path.join(FIG_DIR, \"force_lgb_ultra\")\n",
    "save_force_clean(sv_xgb, fx_path, top_k=12, figsize=(19.0, 3.1))\n",
    "save_force_clean(sv_lgb, fl_path, top_k=12, figsize=(19.0, 3.1))\n",
    "\n",
    "# ---------- Stack the Two Force Plots (Vertical Arrangement) ----------\n",
    "import matplotlib.image as mpimg\n",
    "safe_name = re.sub(r\"[^A-Za-z0-9_.-]+\",\"_\", str(target_key))\n",
    "stack_base = os.path.join(FIG_DIR, f\"fig_local_force_stack_{ID_COL}_{safe_name}\")\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(19, 7.4))\n",
    "axs[0].imshow(mpimg.imread(fx_path + \".png\")); axs[0].set_axis_off(); axs[0].set_title(\"a. XGB Force (wide)\")\n",
    "axs[1].imshow(mpimg.imread(fl_path + \".png\")); axs[1].set_axis_off(); axs[1].set_title(\"c. LGB Force (wide)\")\n",
    "fig.suptitle(f\"Local explanation — {ID_COL}: {target_key}\", y=0.98, fontsize=14)\n",
    "plt.tight_layout(rect=[0,0,1,0.965])\n",
    "_safe_save(fig, stack_base)\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"[Saved] XGB force  ->\", fx_path + \".png\")\n",
    "print(\"[Saved] LGB force  ->\", fl_path + \".png\")\n",
    "print(\"[Saved] Force-wide stack ->\", stack_base + \".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609b1c72-1ba0-45d5-a95e-e890437a8eef",
   "metadata": {},
   "source": [
    "## 8) Local SHAP — Waterfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b83c42df-d074-4cca-8950-d65f6130742b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Saved] Waterfall-row -> ./runs_demo/stage6_explain1/fig_local_waterfall_row_RGI_RGI01.png\n"
     ]
    }
   ],
   "source": [
    "import os, re, numpy as np, shap, matplotlib as mpl, matplotlib.pyplot as plt, matplotlib.image as mpimg\n",
    "\n",
    "SAVE_DIR = \"./runs_demo\"\n",
    "FIG_DIR  = os.path.join(SAVE_DIR, \"stage6_explain1\")\n",
    "os.makedirs(FIG_DIR, exist_ok=True)\n",
    "\n",
    "# Reuse sv_xgb, sv_lgb, ID_COL, and target_key from Cell 7a (Run Cell 7a if these variables are not in memory)\n",
    "\n",
    "# Uncomment the following block if you want this cell to run independently:\n",
    "# try:\n",
    "#     sv_xgb, sv_lgb\n",
    "# except NameError:\n",
    "#     raise RuntimeError(\"Please run Cell 7a first to generate sv_xgb / sv_lgb / ID_COL / target_key\")\n",
    "\n",
    "# ---------- Shared x-axis Waterfall Plot ----------\n",
    "mpl.rcParams.update({\"font.family\":\"DejaVu Sans\",\"font.size\":11})\n",
    "\n",
    "WATERFALL_FIGSIZE = (7.6, 5.2)\n",
    "WATERFALL_LEFT, WATERFALL_RIGHT, WATERFALL_TOP, WATERFALL_BOTTOM = 0.56, 0.98, 0.90, 0.18\n",
    "TOPK_WATERFALL = 10\n",
    "\n",
    "def _safe_save(fig, base):\n",
    "    for ext in (\"png\",\"pdf\",\"svg\"):\n",
    "        fig.savefig(f\"{base}.{ext}\", bbox_inches=\"tight\", dpi=320)\n",
    "\n",
    "def save_waterfall_shared(sv, out_base, shared_xlim=None, max_display=10):\n",
    "    shap.plots.waterfall(sv, max_display=max_display, show=False)\n",
    "    fig = plt.gcf(); ax = plt.gca()\n",
    "    fig.set_size_inches(*WATERFALL_FIGSIZE)\n",
    "    fig.subplots_adjust(left=WATERFALL_LEFT, right=WATERFALL_RIGHT,\n",
    "                        top=WATERFALL_TOP, bottom=WATERFALL_BOTTOM)\n",
    "    ax.xaxis.set_major_locator(mpl.ticker.MaxNLocator(nbins=6))\n",
    "    ax.xaxis.set_major_formatter(mpl.ticker.FuncFormatter(lambda x, pos: f\"{x:.0f}\"))\n",
    "    if shared_xlim is not None:\n",
    "        ax.set_xlim(shared_xlim)\n",
    "    fig.canvas.draw(); _safe_save(fig, out_base)\n",
    "    xlim = ax.get_xlim(); plt.close(fig); return xlim\n",
    "\n",
    "# Generate temporary plots to get xlim, then use the common range for both models\n",
    "tmp_x = os.path.join(FIG_DIR, \"_wf_tmp_xgb\")\n",
    "tmp_l = os.path.join(FIG_DIR, \"_wf_tmp_lgb\")\n",
    "xlim_x = save_waterfall_shared(sv_xgb, tmp_x, max_display=TOPK_WATERFALL)\n",
    "xlim_l = save_waterfall_shared(sv_lgb, tmp_l, max_display=TOPK_WATERFALL)\n",
    "shared_xlim = (min(xlim_x[0], xlim_l[0]), max(xlim_x[1], xlim_l[1]))\n",
    "\n",
    "wx_path = os.path.join(FIG_DIR, \"waterfall_xgb_shared\")\n",
    "wl_path = os.path.join(FIG_DIR, \"waterfall_lgb_shared\")\n",
    "save_waterfall_shared(sv_xgb, wx_path, shared_xlim=shared_xlim, max_display=TOPK_WATERFALL)\n",
    "save_waterfall_shared(sv_lgb, wl_path, shared_xlim=shared_xlim, max_display=TOPK_WATERFALL)\n",
    "\n",
    "# ---------- Compose: Side-by-Side (1x2) ----------\n",
    "safe_name = re.sub(r\"[^A-Za-z0-9_.-]+\",\"_\", str(target_key))\n",
    "row_base = os.path.join(FIG_DIR, f\"fig_local_waterfall_row_{ID_COL}_{safe_name}\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15.6, 5.6))\n",
    "axs[0].imshow(mpimg.imread(wx_path + \".png\")); axs[0].set_axis_off(); axs[0].set_title(\"b. XGB Waterfall\")\n",
    "axs[1].imshow(mpimg.imread(wl_path + \".png\")); axs[1].set_axis_off(); axs[1].set_title(\"d. LGB Waterfall\")\n",
    "fig.suptitle(f\"Local explanation — {ID_COL}: {target_key}\", y=0.98, fontsize=14)\n",
    "plt.tight_layout(rect=[0,0,1,0.965]); _safe_save(fig, row_base); plt.close(fig)\n",
    "\n",
    "print(\"[Saved] Waterfall-row ->\", row_base + \".png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
